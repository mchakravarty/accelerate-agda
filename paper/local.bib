@article{xi:dml,
  author = "Hongwei Xi",
  title = {{Dependent ML: an approach to practical programming with dependent types}},
  journal = "Journal of Functional Programming",
  year = 2007,
  volume = "17",
  number = "2",
  pages = "215-286"
}

@inproceedings{swierstra-altenkirch:dep-types-for-distr-arrays,
  Author = {Wouter Swierstra and Thorsten Altenkirch},
  Booktitle = {Trends in Functional Programming},
  Title = {Dependent Types for Distributed Arrays},
  Volume = {9},
  Year = {2008}}

@article{swierstra:more-dependent-types,
   author = {Swierstra, Wouter},
   affiliation = {Vector Fabrics},
   title = {More dependent types for distributed arrays},
   journal = {Higher-Order and Symbolic Computation},
   publisher = {Springer Netherlands},
   pages = {1-18},
   year = 2010
}

@misc{peebles:derpa,
  author = {Daniel Peebles},
  title = {A dependently typed model of the {Repa} library in {Agda}},
  howpublished = {\url{https://github.com/copumpkin/derpa}},
  year = 2011
  }

@article{xi:dml-jfp,
  author = {Xi, Hongwei},
  title = {Dependent {ML}: An Approach to Practical Programming with Dependent Types},
  journal = {Journal of Functional Programming},
  volume = 12,
  number = 2,
  year = 2007,
  month = March
}

@inproceedings{Tarditi:2006,
 author = {Tarditi, David and Puri, Sidd and Oglesby, Jose},
 title = {Accelerator: using data parallelism to program {GPUs} for general-purpose uses},
 booktitle = {ASPLOS-XII: Proc.\ of the 12th Intl.\ Conf.\ on Architectural Support for Programming Lang.\ and Operating Systems},
 year = {2006},
 pages = {325--335},
 publisher = {ACM},
 }

@techreport{Catanzaro:EECS-2010-124,
    Author = {Catanzaro, Bryan and Garland, Michael and Keutzer, Kurt},
    Title = {Copperhead: Compiling an Embedded Data Parallel Language},
    Institution = {University of California, Berkeley},
    Year = {2010},
    Number = {UCB/EECS-2010-124},
    URL = {http://www.eecs.berkeley.edu/Pubs/TechRpts/2010/EECS-2010-124.html},
    Abstract = {Modern parallel microprocessors deliver high performance on applications that expose substantial fine-grained data parallelism. Although data parallelism is widely available in many computations, implementing data parallel algorithms in low-level languages is often an unnecessarily difficult task. The characteristics of parallel microprocessors and the limitations of current programming methodologies motivate our design of Copperhead, a high-level data parallel language embedded in Python. The Copperhead programmer describes parallel computations via composition of familiar data parallel primitives supporting both flat and nested data parallel computation on arrays of data. Copperhead programs are expressed in a subset of the widely used Python programming language and interoperate with standard Python modules, including libraries for numeric computation, data visualization, and analysis.
In this paper, we discuss the language, compiler, and runtime features that enable Copperhead to efficiently execute data parallel code. We define the restricted subset of Python which Copperhead supports and introduce the program analysis techniques necessary for compiling Copperhead code into efficient low-level implementations. We also outline the runtime support by which Copperhead programs interoperate with standard Python modules. We demonstrate the effectiveness of our techniques with several examples targeting the CUDA platform for parallel programming on GPUs. Copperhead code is concise, on average requiring 3.6 times fewer lines of code than CUDA, and the compiler generates efficient code, yielding 45-100% of the performance of hand-crafted, well optimized CUDA code.}
}

@inproceedings{keller-etal:repa,
  author = {Keller, Gabriele and Chakravarty, Manuel M.T. and Leshchinskiy, Roman and Peyton Jones, Simon and Lippmeier, Ben},
  title = {Regular, shape-polymorphic, parallel arrays in {Haskell}},
  booktitle = {ICFP '10: Proc.\ of the 15th ACM SIGPLAN Intl.\ Conf.\ on Functional Programming},
  year = {2010},
  publisher = {ACM},
}
