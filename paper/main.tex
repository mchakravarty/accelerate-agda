% 16pages; IFL 2012
%
\documentclass{llncs}
%
\usepackage{amssymb}
\usepackage{cite}
\usepackage{color}
% \usepackage[T1]{fontenc}

%\usepackage{amsmath}
%\usepackage{amsthm}
%\usepackage{proof}
\usepackage{alltt}

% UNICODE in Agda sources: more trouble than it is worth right now!

% \usepackage{bbm}
% \usepackage[greek,english]{babel}
% \usepackage{ucs}
% \usepackage[utf8x]{inputenc}
% %\usepackage{autofe}
% \DeclareUnicodeCharacter{8704}{\ensuremath{\forall}}
% % \DeclareUnicodeCharacter{8594}{\ensuremath{\mathbb{N}}}
% \DeclareUnicodeCharacter{8594}{\ensuremath{\to}}


\usepackage{fancyvrb}

\DefineVerbatimEnvironment{code}{Verbatim}{} % Add fancy options here if you like.
\DefineVerbatimEnvironment{hcode}{Verbatim}{formatcom=\color{blue},frame=leftline} % Add fancy options here if you like.


\begin{document}
%
\title{Agda Meets Accelerate}
\subtitle{Extended Abstract}
\author{Peter Thiemann\inst{1} \and Manuel M. T. Chakravarty\inst{2}}
\institute{
  University of Freiburg, Germany,\\
  \email{thiemann@informatik.uni-freiburg.de}
\and
University of New South Wales, Sydney, Australia,\\
\email{chak@cse.unsw.edu.au}
}

\maketitle              % typeset the title of the contribution

\begin{abstract}  
  Embedded languages in Haskell benefit from a range of type extensions, such as type families, that are subsumed by dependent types. However, even with those type extensions, embedded languages for data parallel programming lack desirable static guarantees, such as static bounds checks in indexing and collective permutation operations.
  
  This raises the question whether embedded languages for data parallel programming would benefit from fully-fledged dependent types, such as those available in Agda. We explored that question by designing and implementing an Agda frontend to Accelerate, an embedded language for data parallel programming aimed at GPUs. We discuss the potential of dependent types in this domain, describe some of the limitations that we encountered, and share some insights from our preliminary implementation.
\end{abstract}
\keywords{programming with dependent types, data parallelism}
\thispagestyle{plain}
\pagestyle{plain}
%
\section{Introduction}
\label{sec:introduction}

Generative approaches to programming parallel hardware promise to combine high-level programming models with high-performance. They are especially attractive for targeting restricted architectures, such as GPUs (graphics processor units), that cannot efficiently execute code aimed at conventional multicore CPUs. Instead, GPUs require a high degree of data parallelism, restricted control flow, and carefully tailored data access patterns to be efficient. Previous work ---for example, Accelerator~\cite{??}, Copperhead~\cite{??}, and Accelerate~\cite{ChakravartyKellerLeeMcdonellGrover2011}--- demonstrates that embedded array languages with a custom code generator can meet those GPU constraints by carefully limiting the embedded language constructs.

Given a host languages with an expressive type system, it is attractive to leverage that type system to express static properties of the embedded language. For example, Accelerate, an embedded array language for Haskell, uses Haskell's recent support for type-level programming like GADTs and type families in that manner~\cite{ChakravartyKellerLeeMcdonellGrover2011}. This is especially important for approaches relying on runtime code generation as we want to mimise the number of potential faults at application runtime, which coincides with the compile time of the embedded language. Moreover, static guaranties hold the potential to improve the predictability of parallel performance.

Dependent types are an emerging approach to certified programming, where invariants are established in the form of types and proved at compile time. Many of Haskell's type-level extensions used in Accelerate approximate various aspects of dependently-typed programming. Hence, it it is natural to ask whether fully-fledged dependent types, such as those provided by Agda, improve the specification of an embedded language like Accelerate, whether they increase the scope of static guarantees, and whether they may be leveraged to predict performance more accurately.

This paper is a first investigation into this topic. It reports of a
partial port of Accelerate to a new, dependently-typed host language,
Agda \cite{Norell2008,BoveDybjerNorell2009}. Agda is particularly
suited to this port because of its foreign function interface to
Haskell, which enables it to directly invoke functionality of
Accelerate. 

Our investigation has the following structure. After recalling some
background on Agda and Accelerate in Section~\ref{sec:background} and
describing related work in Section~\ref{sec:related-work}, 
Section~\ref{sec:dependent-types} discusses potential uses of
dependent types in an array-oriented data parallel language like
Accelerate. Section~\ref{sec:limitations} considers conceptual
problems and limitations that we ran into when constructing the Agda
frontend for Accelerate. Section~\ref{sec:implementation} explains
some technical details of the implementation and discusses some
example code. 

\section{Background}
\label{sec:background}

\subsection{Agda}
\label{sec:agda}

Agda \cite{Norell2008,BoveDybjerNorell2009} is a dependently-typed
functional programming language. Its basis is a dependently-typed
lambda calculus extended with inductive data type families, dependent
records, and parameterized modules. At the same time, Agda is also a
proof assistant for interactively constructing proofs in an
intuitionistic type theory based on the work of Per Martin-L\"of
\cite{MartinLoef1984}. 

A familiar example for an indexed data type is the type
\verb+Vec A n+ for vectors of fixed length \verb+n+ and elements of
type \verb+A+ program program with an access operation that restricts the index to the
actual length of the vector at compile time.\footnote{An
  identifier can be an almost arbitrary 
  string of Unicode characters except spaces, parentheses, and curly
  braces. Agda also supports mixfix syntax with the position of
  arguments indicated by underscores in the defining occurrence of an
  identifier.} 
\begin{verbatim}
data Vec (A : Set) : Nat -> Set where
  []   : Vec A zero
  _::_ : {n : Nat} -> A -> Vec A n -> Vec A (suc n)
\end{verbatim}
The above defines an indexed data type \verb+Vec A n+ with two
constructors, \verb+[]+ for the vector of length zero and 
\verb+_::_+ for the infix cons operator that increases the length by one.

One way of writing a safe access operation first defines an indexed
type that encodes the required less-than relation on natural numbers.
\begin{verbatim}
data _<_ : Nat -> Nat -> Set where
  z<s : {n : Nat} -> zero < suc n
  s<s : {m n : Nat} -> m < n -> suc m < suc n
\end{verbatim}
Lines two and three of the definition encode named inference rules for
the cases that $0 < n+1$ (for all $n$) and that $m+1 < n+1$ if $m < n$
(for all $m,n$).

The access operation takes a vector of length \verb+n+, an index
\verb+m+, and a proof of \verb+m < n+ (a derivation tree) to produce
an element of the vector.  
\begin{verbatim}
get : {A : Set} {n : Nat} -> Vec A n -> (m : Nat) -> m < n -> A
get []        _       ()      -- impossible case
get (x :: xs) zero    p       = x
get (x :: xs) (suc m) (s<s p) = get xs m p
\end{verbatim}
This code cannot fail at run time because a caller has to
construct the proof tree for \verb+m < n+ before invoking \verb+get+.

\subsection{Accelerate}
\label{sec:accelerate}

Accelerate~\cite{ChakravartyKellerLeeMcdonellGrover2011} is a
data-parallel array language embedded into Haskell, which targets
GPUs. It is a \emph{generative library}, as its data-parallel array
operations are not executed directly, but instead construct abstract
syntax trees (AST) representing an entire data-parallel
subcomputation. These \emph{computation representations} are executed
using a \verb+run+ operation that accepts such an AST (of type
\verb+Acc a+), compiles it to GPU kernels, uploads it to the device,
executes it, and retrieves the results.\footnote{To distinguish
  Haskell code from Agda code, we display the former in blue and with
  a vertical bar on the left side.}
%
\begin{hcode}
CUDA.run :: Arrays a => Acc a -> a
\end{hcode}
%
The type class constraint \verb+Arrays a+ restricts the result type to a single array or a tuple of arrays.

As computation representations of type \verb+Acc a+ are compiled at application runtime, all \verb+Acc+ compilation errors are effectivly \emph{runtime errors} of the application. Hence, Accelerate uses a range of Haskell type system extensions to statically type Accelerate expressions, such that these runtime errors are avoided where possible. In particular, Accelerate uses GADTs\cite{PeytonJonesVytiniotisWeirichWashburn2006}, associated types
\cite{ChakravartyKellerJones2005}, and type families
\cite{SchrijversPeytonJonesChakravartySulzmann2008}. 

As a simple example of an Accelerate program, consider a function implementing a dot product:
%
\begin{hcode}
dotp :: Vector Float -> Vector Float -> Acc (Scalar Float)
dotp xs ys = let xs' = use xs
                 ys' = use ys
             in  fold (+) 0 (zipWith (*) xs' ys')
\end{hcode}
%
The types \verb+Vector+ and \verb+Scalar+ represent one- and zero-dimensional
arrays. Plain arrays, such as \verb+Vector Float+ are conventional Haskell arrays, using an unboxed representation to improve performance. However, when they are wrapped into the constructor \verb+Acc+, such as in \verb+Acc (Scalar Float)+, they represent arrays of the embedded language and are allocated in GPU memory, which in current high-performance GPUs is physically separate from CPU memory.

The \verb+use+ operation makes a Haskell array available in the embedded language by wrapping it into the \verb+Acc+ constructor and copying it to GPU memory.\footnote{Accelerate employs a caching strategy to avoid the transfer of arrays, which are already available in GPU memory.} The operations \texttt{fold} and \texttt{zipWith} represent collective operations on Accelerate arrays, effectively producing a representation of an array computation yielding a value of
\texttt{Scalar Float}; i.e., a single float value. This code relies
heavily on (type class) overloading: \texttt{0}, \texttt{(+)}, and
\texttt{(*)} are overloaded to just construct abstract syntax. 

The type \verb+Scalar+ and \verb+Vector+ are merely type synonyms instantiating a shape-parameterised array type to the special case of zero and one dimensional arrays:
%
\begin{hcode}
type Scalar e = Array DIM0 e
type Vector e = Array DIM1 e
\end{hcode}
%
So, the general type for \verb+use+ is
%
\begin{hcode}
use :: Elt e => Array sh e -> Acc (Array sh e)
\end{hcode}
%
where the class \verb+Elt+ characterises all types that may be held in Accelerate arrays. These are currently primitive types and tuples.

Common dimensions, such as \verb+DIM0+, \verb+DIM1+, and so on, are predefined, but to enable shape polymorphic computations, along the lines pioneered in the Haskell array library Repa~\cite{keller-etal:repa}, shapes are inductively defined using type-level snoc lists formed from
%
\begin{hcode}
data Z       = Z
data sh :. i = sh :. i
\end{hcode}
%
Hence, we have got
%
\begin{hcode}
type DIM0 = Z
type DIM1 = DIM0 :. Int
-- <and so on>
\end{hcode}

\section{Related Work}
\label{sec:related-work}

Dependent types for array programming: 
\begin{itemize}
\item "Dependent Types for Distributed Arrays".
Wouter Swierstra and Thorsten Altenkirch. Postproceedings of TFP 2008.
\item "More Dependent Types for Distributed Arrays".
Wouter Swierstra. Accepted for publication in the Journal of Higher-order and Symbolic Computation.
\end{itemize}
This work focuses on describing distribution strategies using dependent types (which is orthogonal to our work). However, to characterise distributions, it also tracks bounds in types.

DML:
\begin{itemize}
\item Xi, Hongwei (March 2007). "Dependent ML: An Approach to Practical Programming with Dependent Types". Journal of Functional Programming 17 (2). [There is a previous ICFP paper co-authored with his advisor Bob Harper.]
\end{itemize}
Extension of ML to track array bounds.

Other embedded array languages:
\begin{itemize}
\item Accelerator: C++ library providing data-parallel GPU programming; subsequent work by Satnam Singh provides an F\# binding (but that was never published as for as I know---double check); the language provides only a small subset of the functionality of Accelerate
\item Copperhead: embedded array language in Python; no static guarantees; performance varied widely in our experiments
\item anything else?
\end{itemize}


\section{Dependent Types for Accelerate}
\label{sec:dependent-types}

In this section, we investigate the potential uses of dependent typing
in a language like Accelerate. First, we review some basics of the
embedding. 

\subsection{Embedding of Haskell Types}
\label{sec:embedding-types}

Accelerate supports a wide range of numeric types as base types for
array computations. Almost all of these types have no suitable
counterpart in Agda, which only supports natural numbers in unary
encoding. For that reason, our embedding keeps the Haskell types
abstract in Agda. To specify type signatures and in particular
functions that are polymorphic in such a Haskell type or depend on it
in some way, we have reified these types in an Agda type
\texttt{Element}.
\begin{verbatim}
data Element : Set where
  Bool   : Element
  Int    : Element
  Float  : Element
  Double : Element
  Pair   : Element -> Element -> Element
  -- and so on
\end{verbatim}
Corresponding to Haskell type classes that are used in Accelerate, our
embedding supplies predicates that characterize subsets. For example,
the set of numeric types is defined by a predicate \texttt{IsNumeric}.
\begin{alltt}
IsNumeric : Element -> Set
IsNumeric Int = \(\top\)
IsNumeric Float = \(\top\)
IsNumeric Double = \(\top\)
IsNumeric _ = \(\bot\)
\end{alltt}
The embedding declares further subsets all in the same style.

\subsection{Array Types}
\label{sec:array-types}

To see the Agda embedding in action, we translate the
dot product example from Section~\ref{sec:accelerate} to Agda.
\begin{code}
dotp : {E : Element} {{p : IsNumeric E}} {n : Nat}
     -> PreVector n E -> PreVector n E -> Scalar E
dotp{E} xs ys = 
  let xs' = use xs
      ys' = use ys
  in
  fold _+_ ("0" ::: E) (zipWith _*_ xs' ys')
\end{code}
Unlike the Accelerate code, this function is polymorphic with respect
to the array element type, provided it is numeric. It furthermore
takes the length $n$ as a parameter thus ensuring that the two input
vectors have the same size. The \texttt{PreVector} type of the
arguments corresponds to the plain \texttt{Vector} type in Accelerate,
whereas the result type \texttt{Scalar E} corresponds to \texttt{Acc
  (Scalar E)}---a piece of abstract syntax. 

The \texttt{use} function works as before, but its type
includes more information:
\begin{code}
use : {sh : Shape}{E : Element} -> PreArray sh E -> Array sh E
\end{code}
Like \texttt{E}, the index \texttt{sh} is now an element of an ordinary type:
\begin{verbatim}
data Shape : Set where
  Z     : Shape
  _:<_> : Shape -> Nat -> Shape
\end{verbatim}
Asking for arrays of equal shape, as in the signature of \texttt{use},
means that the arrays have to have the exact same layout.
The functions \texttt{fold}, \texttt{zipWith}, and \texttt{:::} are
discussed in the subsequent Subsections. The functions \verb|_+_| and
\verb|_*_| both have the same type:
\begin{code}
_+_ : {E : Element} {{p : IsNumeric E}} -> Exp E -> Exp E -> Exp E
\end{code}
They are restricted to arguments of numeric type and construct
abstract syntax for an addition or a multiplication by delegating to
the corresponding Accelerate functions.



\subsection{Exact Checking of Array Bounds}
\label{sec:exact-checking-array}

Accelerate's API features expressive type constraints that describe
the shape of the array arguments and results. These constraints ensure
that no shape mismatches occur (e.g., a one-dimensional array cannot be
considered two-dimensional). However, they do not ensure at compile
time that the sizes of the dimensions match up.

As an example, consider the function \texttt{reshape}. 
It takes a target shape \texttt{sh} and an array of source shape
\texttt{sh'} and changes the layout of that array to \texttt{sh}. 
\begin{hcode}
reshape :: Exp sh -> Acc (Array sh' e) -> Acc (Array sh e)
\end{hcode}
For this reshaping to work correctly, the underlying
number of elements must remain the same. For example, while it makes sense
to reshape a two-dimensional $3\times 4$-array  to a vector of size
$12$ or to a three-dimensional $3\times2\times2$-array, whereas an attempt to
reshape the same array to a $2\times5$-array should be rejected at
compile time.

As \texttt{Shape} is an ordinary data type, we can define a
\texttt{size} function that computes the number of elements stored in
an array of a certain shape.
\begin{verbatim}
size : Shape -> Nat
size Z = 1
size (sh :< n >) = size sh * n
\end{verbatim}
Now we can state an accurate type for \texttt{reshape} in Agda, which
involves an extra argument with a proof that the source and
target shapes have the same size.\footnote{For the moment, the type
  \texttt{Element} could be read as \texttt{Set}. Actually,
  \texttt{Element} classifies the types of values that can be stored
  in Accelerate arrays. In Haskell, this restriction is imposed with a
  type class.}
\begin{verbatim}
reshape : {sh : Shape} {E : Element}
       -> (sh' : Shape) -> Array sh E -> (size sh = size sh')
       -> Array sh' E
\end{verbatim}
There is a subtle difference to the original signature. In
Accelerate, the first argument is an \emph{expression} that produces a
value of type \texttt{sh} at run time, whereas the Agda
\texttt{reshape} requires a \texttt{Shape} as its first argument.


Furthermore, functions like \texttt{map} and \texttt{zipWith} obtain
more precise types. The type of \texttt{map} tells us that the input
shape is identical to the output shape:
\begin{verbatim}
map : {A B} {sh} -> (Exp A -> Exp B) -> Array sh A -> Array sh B
\end{verbatim}
Similarly, the type of \texttt{zipWith} restricts its input arrays to
identical shapes:
\begin{verbatim}
zipWith : {A B C} {sh} -> (Exp A -> Exp B -> Exp C)
        -> Array sh A -> Array sh B -> Array sh C
\end{verbatim}
The latter type is more restrictive than the Accelerate
implementation of \texttt{zipWith}. Instead of checking the dimensions
of the input arrays, it truncates them to the respective minima. A
corresponding Agda type could be developed easily. It would involve
specifying a suitable ternary relation between shapes.

\subsection{Associativity of Operations}
\label{sec:assoc-oper}

Some parallel reduction operations require their base operation to be
associative to return a predictable result. Here are two examples from
Accelerate. 
\begin{hcode}
fold  :: (Shape ix, Elt a) =>
         (Exp a -> Exp a -> Exp a) -> Exp a ->
         Acc (Array (ix :. Int) a) -> Acc (Array ix a)
fold1 :: (Shape ix, Elt a) =>
         (Exp a -> Exp a -> Exp a) ->
         Acc (Array (ix :. Int) a) -> Acc (Array ix a)
\end{hcode}
In both cases, the text of the documentation says that ``the first
argument needs to be associative'' and the \texttt{fold1}
documentation ``requires the reduced array to be non-empty''.
The second requirement can be enforced by asking for a suitable proof
object on each call of \texttt{fold1}:
\begin{verbatim}
fold1 : ... -> Array (sh :< n >) E -> (p : size sh * n > 0)
            -> Array sh E
\end{verbatim}
The first requirement can be rephrased to saying that the first two
parameters of \texttt{fold} together form a monoid, which requires an
associative operation with a unit element. The concept of a monoid
can be formalized in Agda, which has indeed been done in the standard
library. Unfortunately, the formalization from the library cannot be
used because Accelerate deals with ASTs, not with values. So, a
formalization is required that states that the meaning of an
AST-encoded function is associative and the meaning of another
AST-encoded constant is its unit element. Given that Accelerate
encodes AST construction using higher-order abstract syntax, such a
formalization is not straightforward. Moreover, even given expressions
with a fixed meaning, there is no general shape for associative
functions, so that proofs can only be done for special cases. 

In any case, providing such information would be done by including an
additional argument that holds a suitable proof object, as in
\begin{verbatim}
fold : {E}{sh}{n} -> (f : Exp E -> Exp E -> Exp E) -> (e : Exp E)
     -> Array (sh :< n >) E -> IsMonoid f e -> Array sh E
\end{verbatim}
where
\begin{verbatim}
IsMonoid : {E} -> (f : Exp E -> Exp E -> Exp E) -> (e : Exp E) -> Set
IsMonoid f e = ( IsAssociative f , IsUnit f e)
\end{verbatim}

\subsection{Embedding of Constants}
\label{sec:embedding-constants}


Accelerate relies on Haskell's built-in support for the type classes
\texttt{Num} and \texttt{Fractional} to embed constants. The Haskell compiler reads each integer
literal as a value of type \texttt{Integer}, which is a built-in type
of arbitrary precision integers. To this value, Haskell applies the
function \texttt{fromInteger} that converts to the expected
type. Similarly, floating point constants are read as values of
type \texttt{Rational} (\texttt{Integer} fractions) and then converted
using \texttt{fromRational}. Accelerate provides instances of
these type classes that define \texttt{fromInteger} and
\texttt{fromRational} to produce suitable AST fragments.

Because of Agda's limited support for numeric data types,
we embed more ambitious numeric literals for floating point numbers
using a string with an explicit type annotation that determines the
parsing of the string. Here are some example embeddings:
\begin{verbatim}
"3.1415926" ::: Float
"6.0221415E23" ::: Double
\end{verbatim}
Recall that \texttt{Float} and \texttt{Double} are not
types, but rather values of type \texttt{Element}.
All magic of the embedding is hidden in the \texttt{:::} operation:
\begin{verbatim}
_:::_ : (s : String) -> (E : Element) 
     -> {{nu : IsNumeric E}} -> {p : T (s parsesAs E)} -> Exp E
s ::: E = Ex (constantFromString (EltDict E) (ReadDict E) s)
\end{verbatim}
The arguments \texttt{s} and \texttt{E} are explicit, but the
remaining ones are to be inferred by Agda.
The argument \texttt{nu} is an instance argument that is automatically
filled-in with a suitably typed value in scope
\cite{DevriesePiessens2011}. Here, the predicate 
\texttt{IsNumeric} plays the role of a type class that characterizes
the numeric types.

The function \texttt{parsesAs} dispatches on its ``type'' argument and
checks whether the string is a constant of the expected type. The
function \texttt{constantFromString} is imported from Accelerate.
It is an overloaded function that requires two type dictionaries,
which are computed from \texttt{E} using the functions \texttt{EltDict}
and \texttt{ReadDict}. 

\section{Limitations}
\label{sec:limitations}

In a number of places, Accelerate's generativity limits the
applicability of dependent typing. We already mentioned that the
formalization of associativity or of the concept monoid gets
unmanageable because such properties have to be asserted for abstract syntax.

For a similar problem, consider an implementation of the \texttt{filter}
operation that takes a predicate and a source array and returns an
array that only contains the elements of the source array fulfilling
the predicate.  First of all, filtering only makes sense for
one-dimensional arrays, that is, for vectors. To see the second catch,
let's try to write down a dependent type signature for \texttt{filter}.
\begin{verbatim}
filter : {n m : Nat}{E : Element}
       -> Vector n E -> (Exp E -> Exp Bool) -> Vector m E
\end{verbatim}
The problem is that the size of the result
cannot be determined statically. In fact, the only thing we know about
\texttt{m} is that it must be less than or equal to
\texttt{n}. However, we cannot prove this from the code because the
Accelerate implementation computes the length of the result in a quite
subtle way. Moreover, as Accelerate deals with the construction of
abstract syntax most of the time, the value of \texttt{m} is simply
not available at run time of \texttt{filter}. 

One might contemplate that an existential type like
\begin{verbatim}
exists Nat (\ m -> m <= n -> Vector m E)
\end{verbatim}
could be employed. However, it is not possible to build such an
existential package because the evidence \texttt{m} is not available
when the package is constructed.

However, an alternative encoding of arrays can be
used which is compatible with filtering of elements. The idea of this
encoding is to keep all elements but mark those which are no longer
present because they have been filtered out.
There are several ways of implementing this idea. The simplest
approach is to wrap each element in a maybe type.
pair up each element with a boolean flag that indicates
its presence.\footnote{A \texttt{Maybe} type would be a better option,
  but it has to be coded without using pattern matching.}
\begin{verbatim}
FVector : Nat -> Element -> Set
FVector n E = Vector n (Pair Bool E)
\end{verbatim}

Now filtering becomes quite simple.
\begin{verbatim}
filterF : {n : Nat}{E : Element}
        -> (Exp E -> Exp Bool) -> FVector n E -> FVector n E
filterF {n}{E} pred vec =
  map g vec
  where
  g : Exp (Pair Bool E) -> Exp (Pair Bool E)
  g bx = pair ((fst bx) && p (snd bx)) x
\end{verbatim}
However, mapping becomes more complicated because it either has to
materialize a dummy result for each absent element in the argument
vector or apply the function to absent elements, too.\footnote{This
  complication could be avoided with the \texttt{Maybe} type.}
\begin{verbatim}
mapF : {n : Nat}{E F : Element}
     -> Exp F -> (Exp E -> Exp F) -> FVector n E -> FVector n F
mapF {n}{E}{F} defaultF f vec =
  map g vec
  where
  g : Exp (Pair Bool E) -> Exp (Pair Bool F)
  g bx = if (fst bx) then (pair (fst bx) (f (snd bx)))
                     else (pair (fst bx) defaultF)
\end{verbatim}
On the positive side, some operations can get rid of the absent
elements. In particular, a fold operation which reduces a filtered
vector with a monoid returns a single value. In Accelerate, such a value has type
\texttt{Scalar}, which is a synonym for an array of dimension $0$.
\begin{verbatim}
foldF : {n : Nat}{E : Element}
      -> (Exp E -> Exp E -> Exp E) -> Exp E
      -> FVector n E -> Scalar E
foldF f e vec =
  fold f e (map (\ bx -> if (fst bx) then (snd bx) else e) vec)
\end{verbatim}
Other operations like \texttt{fold1} and the scan operations present
in Accelerate can also be lifted to this representation, but they
retain a notion of absent elements and do not allow to revert to a
non-filtered representation. 

In the end, such a representation may not be a loss on a GPU. As long
as all computations take the same path, all processing elements work
in unison. As soon as there are different paths in the same
computation step, then some elements will be idle for part of the
computation step. So it would be most advantageous to organize work as
uniformly as possible. 


\section{Implementation}
\label{sec:implementation}

Ordinarily, Agda is an interactive tool for constructing proofs and
verified programs. Programs may be run, which amounts to normalizing
Agda expressions, but this process is not very efficient.

Alternatively, an interactively developed program may be compiled to
Haskell using the Alonzo compiler. This compiler supports a Haskell
foreign function interface (FFI), which enables Agda programs to invoke
Haskell functions. 

Using this interface amounts to declaring a typed identifier in Agda
and then binding the identifier to a suitably typed Haskell
function. As an example, consider the import of the \texttt{use}
function.
\begin{code}
postulate 
  useHs : {E : Set}
      -> HsEltDict E -> HsArray HsDIM1 E -> Acc (AccArray HsDIM1 E)
  {-# COMPILED useHs       (\ _ -> Accel.use) #-}
\end{code}
The first three lines introduce the typed identifier \texttt{useHs}
and the last line is a pragma for the Alonzo compiler that binds the
Agda identifier \texttt{useHs} to the Haskell expression on the right.
But wait, this type looks very unpleasant and quite different to the
one mentioned in Section~\ref{sec:array-types}. This difference arises
because the type translation of Alonzo is unable to cope with the
index type \texttt{Shape}. For that reason, the interface uses a
simplified array type and adapter functions are required, both on the
Agda side and on the Haskell side of the interface.

At the foreign function interface level, all arrays are considered as
one-dimensional arrays. Additional arguments are passed to encode the
additional structure. The Agda adapter provides the encoding of this
structure and the Haskell adapter decodes it again. 

We believe that these adapations only have a minor performance impact
because (1) most functions just manipulate abstract syntax, so that
only AST construction is affected, and (2) internally, Accelerate
considers all arrays as one-dimensional so that operations like
\texttt{reshape} are no-ops at run time.

Here is the Agda adapter for \texttt{use}:
\begin{verbatim}
use : {sh : Shape}{E : Element} -> PreArray E sh -> Array E sh
use {sh}{E} (PA y) = Ar (useHs (EltDict E) y)
\end{verbatim}
It makes use of two wrapper types. \texttt{PreArray} wraps a
one-dimensional Haskell using the constant \texttt{HsDIM1} (the
\texttt{DIM1} type shown in Section~\ref{sec:accelerate} imported from
Haskell via FFI) and the function \texttt{EltType} (not shown), which
interprets a value of type \texttt{Element} as a Haskell type. The
latter types are also imported via FFI.
\begin{code}
data PreArray (Elt : Element) : Shape -> Set where
  PA : {sh : Shape}
     -> HsArray HsDIM1 (EltType Elt) -> PreArray Elt sh
\end{code}
The \texttt{Array} type wraps an AST reference for an Accelerate
array, where \texttt{Acc} and \texttt{AccArray} are types imported
from Haskell.
\begin{code}
data Array (Elt : Element) : Shape -> Set where
  Ar : {sh : Shape}
     -> Acc (AccArray HsDIM1 (EltType Elt)) -> Array Elt sh
\end{code}
The \texttt{EltDict} function translates a value 
\texttt{(E : Element)} into a Haskell expression that evaluates to a
dictionary for the Haskell type of \texttt{E} for the Haskell type
class \texttt{Elt}. Such a dictionary is passed, whenever that
corresponding Haskell function has type class constraints.
\begin{code}
EltDict : (E : Element) -> HsEltDict (EltType E)
\end{code}

The Haskell side of the adapter has several purposes. First, it
materializes the type class dictionaries from the encoding that we
just discussed. Second, it reconstructs sufficient information about
the array shape so that the intended operation can execute. Here is
the code for \texttt{Accel.use}, where the module name \texttt{A}
is a shorthand for \texttt{Data.Array.Accelerate}.
\begin{hcode}
use :: EltDict e -> Array A.DIM1 e -> A.Acc (A.Array A.DIM1 e)
use EltDict (ARRAY ar) = (A.use ar)
\end{hcode}
It does not have to reconstruct any information except the type class
constraint. This constraint is materialized using the type
\texttt{EltDict} below.
\begin{hcode}
data EltDict e where
  EltDict :: (A.Elt e) => EltDict e
\end{hcode}
This datatype is built such that each value captures the \texttt{Elt}
dictionary of type \texttt{e}. It remains to build such values for all
types that we want to transport across the FFI. These are the values
used by the (Agda) \texttt{EltDict} function. Here are two examples.
\begin{hcode}
eltDictBool :: EltDict Bool
eltDictBool = EltDict

eltDictInt :: EltDict Int
eltDictInt = EltDict
\end{hcode}

As an example for a function that require more work on either side,
consider the \texttt{fold} operation. 
\begin{code}
fold : {E}{sh}{n}
     -> (Exp E -> Exp E -> Exp E)
     -> Exp E
     -> Array E (sh :< n >)
     -> Array E sh
fold {E}{sh}{n} f (Ex e) (Ar a) =
  Ar (foldHs (EltDict E) (toHsInt (size sh)) (toHsInt n)
             (unwrap2 f) e a)
\end{code}
As values of type \texttt{Exp} also need a wrapper type in Agda (it is
not possible to import type constructors via the FFI), there is some
unwrapping going on for the \texttt{e} and \texttt{f}
arguments. The implementation of \texttt{fold} just calls the
\texttt{foldHs} function and encodes the information about the shape
in two number arguments. Here, \texttt{size sh} is the size of the
result and \texttt{n} is the size of the dimension that is folded. As
these values are first available as Agda natural numbers, they need to
be converted to Haskell numbers using the function \texttt{toHsInt}.

The \texttt{foldHs} function is defined via the FFI.
\begin{code}
postulate
  foldHs : {A : Set}
          -> HsEltDict A
          -> HsInt
          -> HsInt
          -> (AccExp A -> AccExp A -> AccExp A)
          -> AccExp A
          -> Acc (AccArray HsDIM1 A)
          -> Acc (AccArray HsDIM1 A)
  {-# COMPILED foldHs      (\_ -> Accel.fold) #-}
\end{code}
The Haskell adapter needs to reconstruct the \texttt{Elt} dictionary
as before, but it also needs to reshape the one-dimensional array
representation into a two-dimensional one for executing the fold
operation. The two size arguments are required for exactly this
reshape operation. With that insight, the code is straightforward.
\begin{hcode}
fold :: EltDict a
     -> Int -> Int
     -> (A.Exp a -> A.Exp a -> A.Exp a)
     -> A.Exp a
     -> A.Acc (A.Array A.DIM1 a)
     -> A.Acc (A.Array A.DIM1 a)
fold EltDict size2 size1 f e a =
     (A.reshape (A.lift (A.Z A.:. size2))
      (A.fold f e
       (A.reshape (A.lift (A.Z A.:. size2 A.:. size1)) a)))
\end{hcode}

Fortunately, the \texttt{fold} example is about as complicated as the
adapter code gets. There are also many cases where at least one side
of the adapter code is trivial. However, each case must be considered
separately. 

\section{Conclusion}
\label{sec:conclusion}

We have build an experimental Agda frontend for the Accelerate
language. The goal of this experiment was to explore potential uses of
dependently-typed programming for data-parallel languages. 

At the moment, the outcome of the experiment is mixed. It is
successful, because we have been able to construct Agda functions for
a representative sample of Accelerate's functionality.
However, there was less scope for encoding extra information in the
dependent types than we had hoped for. Exact matching of array bounds
works, but results in restrictions (like the problems with
\texttt{zipWith} and filtering) that were not anticipated.

Exploiting algebraic properties did not work out in the intended way, mainly
because it boils down to asserting that some AST denotes an
associative function. However, these assertions cannot be proven: the
proof would have to apply the semantics to the AST, but the AST is an
abstract type in our implementation. An AST representation in Agda
might give us a better handle at this problem. 

In some places, the Agda frontend is less dynamic than Accelerate. In
a number of places, Accelerate accepts a run-time value of type
\texttt{Exp sh} for a shape argument, where the Agda frontend requires
a value of type \texttt{Shape}. To address this problem, we would have
to include a \texttt{Shape}-indexed encoding of the \texttt{Shape}
type in the \texttt{Element} type so that we can describe the type of
an expression whose value has a certain shape. 

Finally, the type translation of Agda's FFI has many shortcomings that
caused a number of problems for transporting information between Agda
and Haskell. One part of the problem is, unfortunately, the rich type
structure of Accelerate which already encodes much useful
information. An alternative, untyped (or less-typed) interface to
Accelerate would make the adaptation to an Agda frontend much simpler.

%
% ---- Bibliography ----
%
\bibliography{abbrevs,papers,books,collections,misc,theses}
\bibliographystyle{abbrv}

\end{document}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% coding: utf-8
%%% End: 
